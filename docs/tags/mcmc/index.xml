<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Mcmc on </title>
    <link>https://liyuantong93.com/tags/mcmc/</link>
    <description>Recent content in Mcmc on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>&amp;copy; 2018 Yuantong Li. All rights reserved.</copyright>
    <lastBuildDate>Wed, 22 Aug 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://liyuantong93.com/tags/mcmc/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Sampling Methods and Monte Carlo methods</title>
      <link>https://liyuantong93.com/2018/08/22/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://liyuantong93.com/2018/08/22/</guid>
      <description>Suppose we have a function \(f(x)\) and weâ€™d like to compute \(E{f(X )} =\int f(x)p(x)dx\), where \(g(x)\) is a density.
There is no guarantee that the techniques we learn in calculus are sufficient to evaluate this integral analytically.
Thankfully, the law of large numbers (LLN) is here to help:
If X1, X2, . . . are iid samples from \(g(x)\), then
\(\frac{1}{n}\sum^{n}_{i=1}f(x_{i}) \rightarrow \int f(x)p(x)dx = E[f(x)]\) with prob 1</description>
    </item>
    
  </channel>
</rss>